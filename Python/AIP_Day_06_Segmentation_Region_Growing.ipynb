{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Advanced Image Processing and Analysis</h1>\n",
    "<h3 align=\"center\">ECE 4438B/ECE 9022/ECE 9202B/BIOMED 9519B/BIOPHYS 9519B/CAMI 9519B</h3>\n",
    "<h4 align=\"center\"><a href=\"mailto:echen29@uwo.ca\"> Elvis Chen, PhD, LL</a></h4>\n",
    "<h4 align=\"center\">Robarts Research Institute, London</h4>\n",
    "<h4 align=\"center\">Department of Electrical and Computer Engineering, Western University</h4>\n",
    "<h4 align=\"center\">School of Biomedical Engineering, Western University</h4>\n",
    "<h4 align=\"center\">Department of Medical Biophysics, Western University</h4>\n",
    "<h4 align=\"center\">Day 06, January 22, 2019</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Region Growing Segmentation\n",
    "\n",
    "It is reasonable that the same class of tissue would exhibit similar pixel intensity within the image. If a **seed** is given, we can group a class of pixels that are similar (by some statistical measures) and in the neighbourhood of the seed. In SimpleITK, thse are some of the filters that perform region growing segmentation. The common theme for all algorithms is that a voxel's neighbour is considered to be in the same class if its intensities are *similar* (by some statistical measures) to the current voxels. The definition of *similarity* is what varies:\n",
    "* <b>ConnectedThreshold</b>: The neighboring voxel's intensity is within explicitly specified thresholds.\n",
    "* <b>ConfidenceConnected</b>: The neighboring voxel's intensity is within the implicitly specified bounds $\\mu\\pm c\\sigma$, where $\\mu$ is the mean intensity of the seed points, $\\sigma$ their standard deviation and $c$ a user specified constant.\n",
    "* <b>VectorConfidenceConnected</b>: A generalization of the previous approach to vector valued images, for instance multi-spectral images or multi-parametric MRI. The neighboring voxel's intensity vector is within the implicitly specified bounds using the Mahalanobis distance $\\sqrt{(\\mathbf{x}-\\mathbf{\\mu})^T\\Sigma^{-1}(\\mathbf{x}-\\mathbf{\\mu})}<c$, where $\\mathbf{\\mu}$ is the mean of the vectors at the seed points, $\\Sigma$ is the covariance matrix and $c$ is a user specified constant.\n",
    "\n",
    "We will illustrate the usage of these three filters using a cranial MRI scan (T1 and T2) and attempt to segment one of the ventricles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use interactive plots (mouse clicks, zooming, panning) we use the nbagg back end. We want our graphs \n",
    "# to be embedded in the notebook, inline mode, this combination is defined by the magic \"%matplotlib notebook\".\n",
    "%matplotlib notebook\n",
    "\n",
    "import SimpleITK as sitk\n",
    "\n",
    "%run update_path_to_download_script\n",
    "from downloaddata import fetch_data as fdata\n",
    "import gui\n",
    "\n",
    "\n",
    "# Using an external viewer (ITK-SNAP or 3D Slicer) we identified a visually appealing window-level setting\n",
    "T1_WINDOW_LEVEL = (1050,500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us experiment what each filter does. Staring with the ConnectedThreshold filter:\n",
    "<ul>\n",
    "  <li><a href=\"http://www.itk.org/Doxygen/html/classitk_1_1ConnectedThresholdImageFilter.html\">ConnectedThreshold</a>: Label pixels that are connected to a seed and lie within a range of values.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data and Select Seed Point(s)\n",
    "\n",
    "We first load a T1 MRI brain scan and select our seed point(s). If you are unfamiliar with the anatomy you can use the preselected seed point specified below, just uncomment the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img_T1 = sitk.ReadImage(fdata(\"nac-hncma-atlas2013-Slicer4Version/Data/A1_grayT1.nrrd\"))\n",
    "img_T1 = sitk.ReadImage(\"..\\\\data\\\\volumes\\\\A1_grayT1.nrrd\")\n",
    "# Rescale the intensities and map them to [0,255], these are the default values for the output\n",
    "# We will use this image to display the results of segmentation\n",
    "img_T1_255 = sitk.Cast(sitk.IntensityWindowing(img_T1, \n",
    "                                               windowMinimum=T1_WINDOW_LEVEL[1]-T1_WINDOW_LEVEL[0]/2.0, \n",
    "                                               windowMaximum=T1_WINDOW_LEVEL[1]+T1_WINDOW_LEVEL[0]/2.0), \n",
    "                       sitk.sitkUInt8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_acquisition_interface = gui.PointDataAquisition(img_T1, window_level=(1050,500))\n",
    "\n",
    "#preselected seed point in the left ventricle  \n",
    "point_acquisition_interface.set_point_indexes([(132,142,96)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_seed_point_indexes = point_acquisition_interface.get_point_indexes()\n",
    "print(initial_seed_point_indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConnectedThreshold\n",
    "\n",
    "We start by using explicitly specified thresholds, you should modify these (lower/upper) to see the effects on the \n",
    "resulting segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(sitk.ConnectedThreshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_explicit_thresholds = sitk.ConnectedThreshold(img_T1, seedList=initial_seed_point_indexes, lower=100, upper=170)\n",
    "# Overlay the segmentation onto the T1 image\n",
    "gui.MultiImageDisplay(image_list = [sitk.LabelOverlay(img_T1_255, seg_explicit_thresholds)],                   \n",
    "                      title_list = ['connected threshold result'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConfidenceConnected\n",
    "\n",
    "This region growing algorithm allows the user to implicitly specify the threshold bounds based on the statistics estimated from the seed points, $\\mu\\pm c\\sigma$. This algorithm has some flexibility which you should familiarize yourself with:\n",
    "* The \"multiplier\" parameter is the constant $c$ from the formula above. \n",
    "* You can specify a region around each seed point \"initialNeighborhoodRadius\" from which the statistics are estimated, see what happens when you set it to zero.\n",
    "* The \"numberOfIterations\" allows you to rerun the algorithm. In the first run the bounds are defined by the seed voxels you specified, in the following iterations $\\mu$ and $\\sigma$ are estimated from the segmented points and the region growing is updated accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(sitk.ConfidenceConnected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a refresh course, let us recall what does [`mean`](https://en.wikipedia.org/wiki/Mean) and [`standard deviation`](https://en.wikipedia.org/wiki/Standard_deviation) of a distribution mean. \n",
    "\n",
    "Assume as we a simple $3\\times 3$ image. This can be a sub-image of a larger image. The center pixel is connected to $8$ neighbouring pixels (hence 8-connected in the documentation of [sitk.ConfidenceConnected](https://itk.org/Doxygen/html/classitk_1_1ConfidenceConnectedImageFilter.html)):"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "|------|------|------|\n",
    "|  128 |  130 |  131 |\n",
    "|------|------|------|\n",
    "|  126 |  131 |  132 |\n",
    "|------|------|------|\n",
    "|  129 |  135 |  133 |\n",
    "|------|------|------|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `mean` is simply the average:\n",
    "\n",
    "$\\mu=\\frac{128   +130+   131+   126+   131+   132+   129+   135+   133}{9} = \\frac{1175}{9} = 130.5556$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The formula for the sample standard deviation is:\n",
    "$\\sigma = \\sqrt{\\frac{\\sum^{N}_{i=1}(x_i-\\mu)^2}{N-1}}$\n",
    "\n",
    "Go through the calculation manually to confirm that the standard deviation is $2.6977$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A voxel in 3D has $26$ adjacent neighbouring voxels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the [ConfidenceConnected](https://itk.org/Doxygen/html/classitk_1_1ConfidenceConnectedImageFilter.html) filter, given a seed, the mean and [variance](https://en.wikipedia.org/wiki/Variance) across a neighbourhood are calculated.  Then any pixel/voxel whose values are within the conficence interval for the seek point are grouped.\n",
    "\n",
    "The width of the confidence interval is controlled by the `multiplier` variable: The confidence interval is the mean $\\pm$ $($`multiplier` $\\times \\sigma$ $)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_implicit_thresholds = sitk.ConfidenceConnected(img_T1, seedList=initial_seed_point_indexes,\n",
    "                                                   numberOfIterations=1,\n",
    "                                                   multiplier=2,\n",
    "                                                   initialNeighborhoodRadius=1,\n",
    "                                                   replaceValue=1)\n",
    "\n",
    "gui.MultiImageDisplay(image_list = [sitk.LabelOverlay(img_T1_255, seg_implicit_thresholds)],                   \n",
    "                      title_list = ['confidence connected result'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this initial segmentation is calculated, the mean and variance are re-calculated. All the pixels in the previous segmentation are used to calculate the mean the standard deviation (as opposed to using the pixels in the neighborhood of the seed point). The segmentation is then recalculated using these refined estimates for the mean and variance of the pixel values. This process is repeated for the specified number of iterations. Setting the `NumberOfIterations` to $0$ stops the algorithm after the initial segmentation from the seed point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VectorConfidenceConnected\n",
    "\n",
    "A [multispectral image](https://en.wikipedia.org/wiki/Multispectral_image) is one that captures image data within specific wavelength ranges across the electromagnetic spectrum. Perhaps the simplest form of multispectral image is the typical RGB pictures: they are represented as an image but the pixel type is a vector.\n",
    "\n",
    "Examples of multispectral imaging in medicine includes [dual-energy CT](https://link.springer.com/article/10.1007%2Fs00330-008-1122-7) and MRI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first load a T2 image from the same person and combine it with the T1 image to create a vector image. This region growing algorithm is similar to the previous one, ConfidenceConnected, and allows the user to implicitly specify the threshold bounds based on the statistics estimated from the seed points. The main difference is that in this case we are using the Mahalanobis and not the intensity difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img_T2 = sitk.ReadImage(fdata(\"nac-hncma-atlas2013-Slicer4Version/Data/A1_grayT2.nrrd\"))\n",
    "img_T2 = sitk.ReadImage(\"..\\\\data\\\\volumes\\\\A1_grayT2.nrrd\")\n",
    "\n",
    "img_T2_255 = sitk.Cast(sitk.IntensityWindowing(img_T2, \n",
    "                                               windowMinimum=T1_WINDOW_LEVEL[1]-T1_WINDOW_LEVEL[0]/2.0, \n",
    "                                               windowMaximum=T1_WINDOW_LEVEL[1]+T1_WINDOW_LEVEL[0]/2.0),\n",
    "                       sitk.sitkUInt8)\n",
    "                       \n",
    "img_multi = sitk.Compose(img_T1, img_T2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_implicit_threshold_vector = sitk.VectorConfidenceConnected(img_multi, \n",
    "                                                               initial_seed_point_indexes, \n",
    "                                                               numberOfIterations=2, \n",
    "                                                               multiplier=4)\n",
    "\n",
    "gui.MultiImageDisplay(image_list = [sitk.LabelOverlay(img_T1_255, seg_implicit_threshold_vector)],                   \n",
    "                      title_list = ['vector confidence connected result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gui.MultiImageDisplay(image_list = [sitk.LabelOverlay(img_T1_255, seg_implicit_threshold_vector),\n",
    "                                    sitk.LabelOverlay(img_T2_255, seg_implicit_threshold_vector)],\n",
    "                      shared_slider=True,\n",
    "                      title_list = ['vector confidence connected result', 'T2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up, Clean up...\n",
    "\n",
    "Use of low level segmentation algorithms such as region growing is often followed by a clean up step. In this step we fill holes and remove small connected components. Both of these operations are achieved by using binary morphological operations, opening (BinaryMorphologicalOpening) to remove small connected components and closing (BinaryMorphologicalClosing) to fill holes.\n",
    "\n",
    "SimpleITK supports several shapes for the structuring elements (kernels) including:\n",
    "* sitkAnnulus\n",
    "* sitkBall\n",
    "* sitkBox\n",
    "* sitkCross\n",
    "\n",
    "The size of the kernel can be specified as a scalar (same for all dimensions) or as a vector of values, size per dimension.\n",
    "\n",
    "The following code cell illustrates the results of such a clean up, using closing to remove holes in the original segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorRadius=(1,1,1)\n",
    "kernel=sitk.sitkBall\n",
    "seg_implicit_thresholds_clean = sitk.BinaryMorphologicalClosing(seg_implicit_thresholds, \n",
    "                                                                vectorRadius,\n",
    "                                                                kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we compare the original segmentation to the segmentation after clean up (using the GUI you can zoom in on the region of interest for a closer look)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gui.MultiImageDisplay(image_list = [sitk.LabelOverlay(img_T1_255, seg_implicit_thresholds), \n",
    "                                sitk.LabelOverlay(img_T1_255, seg_implicit_thresholds_clean)], \n",
    "                  shared_slider=True,\n",
    "                  title_list = ['before morphological closing', 'after morphological closing'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "widgets": {
   "state": {
    "5f80ae352a614ea68f6050ee5e059f34": {
     "views": [
      {
       "cell_index": 25
      }
     ]
    },
    "626c99c73f914375a4aff475bb03d5c6": {
     "views": [
      {
       "cell_index": 10
      }
     ]
    },
    "9a32e4ecb1a04129a5214b9b45fa60c6": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "b104afaf432b4e38890a7146df79da36": {
     "views": [
      {
       "cell_index": 24
      }
     ]
    },
    "b4bc6d47f21741f7aa7b676a636785bf": {
     "views": [
      {
       "cell_index": 6
      }
     ]
    },
    "f633b3cf7cf74214b48e46fdec91e8d6": {
     "views": [
      {
       "cell_index": 19
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
