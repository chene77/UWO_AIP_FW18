{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Advanced Image Processing and Analysis</h1>\n",
    "<h3 align=\"center\">ECE 4438B/ECE 9022/ECE 9202B/BIOMED 9519B/BIOPHYS 9519B/CAMI 9519B</h3>\n",
    "<h4 align=\"center\"><a href=\"mailto:echen29@uwo.ca\"> Elvis Chen, PhD, LL</a></h4>\n",
    "<h4 align=\"center\">Robarts Research Institute, London</h4>\n",
    "<h4 align=\"center\">Department of Electrical and Computer Engineering, Western University</h4>\n",
    "<h4 align=\"center\">School of Biomedical Engineering, Western University</h4>\n",
    "<h4 align=\"center\">Department of Medical Biophysics, Western University</h4>\n",
    "<h4 align=\"center\">Day 06, January 22, 2019</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "By we are have build a few utility functions to assists us in terms of segmentatio and visualization. We also have performed a simple thresholding example based on a chess phantom and imaged in CT. The reason a simple, binary, thresholding technique works well for this phantom (and the fact it is in CT) is because the phantom was made of a single (and dense) material. In CT, it has the characteristic of being bright (i.e. high intensity value) as compared to other objects in the image volume.  The fact that the phantom-bone material was [homogeneous](https://en.oxforddictionaries.com/definition/homogeneous) and solid helped the segmentation process as well.\n",
    "\n",
    "Real tissue, however, is not homogeneous in structure. Take a long [bone](https://en.wikipedia.org/wiki/Bone) such as the femur, as an example, it contains the \n",
    "* [cortical bone](https://en.wikipedia.org/wiki/Bone#Cortical_bone): the hard outer layer of bones\n",
    "* [Cancellous bone](https://en.wikipedia.org/wiki/Bone#Cancellous_bone): the internal tissue of the skeletal bone and is an open cell porous network\n",
    "\n",
    "<a title=\"By Pbroks13 (Own work) [CC BY 3.0 (http://creativecommons.org/licenses/by/3.0)], via Wikimedia Commons\" href=\"https://commons.wikimedia.org/wiki/File%3ABone_cross-section.svg\"><img width=\"512\" alt=\"Bone cross-section\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/1/12/Bone_cross-section.svg/512px-Bone_cross-section.svg.png\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As such, the appearance of bone in CT is not homogeneous either:\n",
    "![test](https://openi.nlm.nih.gov/imgs/512/331/3460560/PMC3460560_ci12904902.png)\n",
    "(Credit of the image goes to [Vanel et al.](https://openi.nlm.nih.gov/detailedresult.php?img=PMC3460560_ci12904902&query=&req=4&simCollection=PMC3460560_ci12904902&npos=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple (binary) thresholding technique may not work in these cases. Fortunately, SimpleITK has many types of segmentation filters that will facilitate us in these scenario.\n",
    "\n",
    "In this Jupyter Notebook, we'll look into some of the image segmenation filters available in SimpleITK that will partition an image into (hopefully) meaningful regions. The goal of this notebook is to become familiar with basic segmentation algorithms avilable in SimpleITK, and interactively explore their parameter space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **output** of the segmentation pipeline is commonly an **image** of integers where each integer can represent an object.  This is commonly as a **label map**.  In this **image**, the value `0` is often used to denote the background, and 1 (sometimes 255) for a foreground object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "#\n",
    "# By now we should know how to import the necessary modules into the Jupyter Notebooks/Python. It is a good practice\n",
    "# to import all modules at the beginning of your python script.\n",
    "#\n",
    "\n",
    "# for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# widgets for interactions\n",
    "from ipywidgets import interact, FloatSlider, fixed\n",
    "\n",
    "\n",
    "# SimpleITK\n",
    "import SimpleITK as sitk\n",
    "\n",
    "# Download data to work on\n",
    "%run update_path_to_download_script\n",
    "from downloaddata import fetch_data as fdata\n",
    "\n",
    "# utilities\n",
    "import os\n",
    "\n",
    "# utilities for diplaying images\n",
    "from myshow import myshow, myshow3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us get some data first. For the purpose of segmentation, load the CT of the chess phantom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ct = sitk.ReadImage(fdata(\"cthead1.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(sitk.StatisticsImageFilter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = sitk.StatisticsImageFilter()\n",
    "stats.Execute(img_ct)\n",
    "print('minimum:', stats.GetMinimum())\n",
    "print('maximum:', stats.GetMaximum())\n",
    "print('mean:', stats.GetMean())\n",
    "print('std.:', stats.GetSigma())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myshow(img_ct)\n",
    "imgPixelID = img_ct.GetPixelID()\n",
    "# print(img_ct.GetPixelID())\n",
    "print(img_ct.GetPixelIDTypeAsString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the file we just read is of `.png` format: as such, the range of the pixel value is already scaled for us to be within [0...255] value. The use of `8-bit unsigned integer` is a hint too. \n",
    "\n",
    "Remember, the [CT Hounsfield Unit](https://en.wikipedia.org/wiki/Hounsfield_scale) for for \n",
    "* distilled at water at standard pressure and temperature (STP) is `0` **by definition**,\n",
    "* air is around `-1000`,\n",
    "* bone:\n",
    "  * +200 in craniofacial bone\n",
    "  * +700 in cancellous bone\n",
    "  * +3000 in cortical bone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mapping the intensity value from Hounsfield Unit (UH) to certain range can be achieved using a simple linear transformation:\n",
    "\n",
    "$outputPixel = (inputPixel-inputMin) \\cdot \\frac{(outputMax - outputMin)}{(inputMax - inputMin)} + outputMin$\n",
    "\n",
    "Suppose in the original CT image a pixel corresponding to the cortical bone has an intensity value of $3000$. The min/max pixel intensity value of the CT image is $-1500$ and $3500$, respectively. If we are to save it as a [`.PNG`](https://en.wikipedia.org/wiki/Portable_Network_Graphics) file format, where each pixel is stored as a 25-bit RGB or 32-bit RGBA color (8-bit per channel), the linearly mapped output pixel intensity is:\n",
    "\n",
    "8-bit implies ($2^8=256$) grayscale values\n",
    "\n",
    "$x = (3000 - (-1500)) \\cdot \\frac{255-0}{3500 - (-1500)} + 0 = 230$\n",
    "\n",
    "This mapping can be done using [sitk.RescaleIntensityImageFilter](https://itk.org/Doxygen/html/classitk_1_1RescaleIntensityImageFilter.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thresholding\n",
    "\n",
    "For the sake of completeness, let us look at thresholding again as it is the most basic form of segmentation. It simply labels the pixels of an image based on the intensity range without respect to geometry or connectivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(sitk.GetArrayViewFromImage(vol)[z,:,:])\n",
    "plt.figure()\n",
    "plt.hist(sitk.GetArrayViewFromImage(img_ct))\n",
    "plt.title(\"Histogram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to visualize the labels image in RGB needs an image with 0-255 range\n",
    "#\n",
    "# we don't need to do this for THIS particular image (it is already rescaled).\n",
    "img_255 = sitk.Cast(sitk.RescaleIntensity(img_ct), sitk.sitkUInt8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason we need to create another image `img_255` is for visualization purposes. A label map (image) is simply an image of integers where each integer value denotes a label. It can be displayed as an RGB picture. As such, using the `sitk.LabelOverlay` function the CT image itself needs to be scaled as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg = img_ct > 220\n",
    "myshow(sitk.LabelOverlay(img_255, seg), \"Basic Thresholding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what doees LabelOverlay do?\n",
    "help(sitk.LabelOverlay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We performed a simple arithmetic operation on the SimpleITK Image class. What is the output of that operation?\n",
    "#help(seg)\n",
    "print(seg.GetPixelIDTypeAsString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While arithemtic operation allows us to perform a thresholding operation, the SimpleITK `BinaryThreshold` class perform thresholding operation with an [lower, upper] bound, and we can assign a value (label) for both inside and outside range of the threshold values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg = sitk.BinaryThreshold(img_ct, lowerThreshold=130, upperThreshold=155, insideValue=1, outsideValue=0)\n",
    "myshow(sitk.LabelOverlay(img_255, seg), \"Binary Thresholding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We instintively choose threshold values based on the histogram of the image. SimpleITK has a number of histogram based thresholding filters that automatically selects a threholding values based on the histogram statistics, such the [maximum entropy](https://www.sciencedirect.com/science/article/pii/0734189X85901252) and the popular [Otsu's method](http://ieeexplore.ieee.org/document/4310076/).\n",
    "\n",
    "[Otsu's method](http://ieeexplore.ieee.org/document/4310076/), for example, assumes that the image contains two classes of pixel following a [bi-model](https://en.wikipedia.org/wiki/Multimodal_distribution) distribution (background and foreground). It then automatically calculates the optimum threshold separating the two classes so that their combined spread (intra-class variance) is minimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "otsu_filter = sitk.OtsuThresholdImageFilter()\n",
    "otsu_filter.SetInsideValue(0)\n",
    "otsu_filter.SetOutsideValue(1)\n",
    "seg = otsu_filter.Execute(img_ct)\n",
    "myshow(sitk.LabelOverlay(img_255, seg), \"Otsu Thresholding\")\n",
    "\n",
    "print(otsu_filter.GetThreshold() )\n",
    "print(img_ct.GetSize())\n",
    "print(seg.GetSize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [maximum entropy](https://www.sciencedirect.com/science/article/pii/0734189X85901252) method, on the other hand, choose a threhold value such that the entropies of distributions above and below the threshold value is maximised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MaxEntropy_Filter = sitk.MaximumEntropyThresholdImageFilter()\n",
    "MaxEntropy_Filter.SetInsideValue(0)\n",
    "MaxEntropy_Filter.SetOutsideValue(1)\n",
    "seg = MaxEntropy_Filter.Execute(img_ct)\n",
    "myshow(sitk.LabelOverlay(img_255, seg), \"Maximum Entropy Thresholding\")\n",
    "print(MaxEntropy_Filter.GetThreshold())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One intersting applimcation is to define a region of interest (ROI) with minimal background with the help of the following filters:\n",
    "\n",
    "* [sitk.LabelShapeStatisticsImageFilter](https://itk.org/SimpleITKDoxygen/html/classitk_1_1simple_1_1LabelShapeStatisticsImageFilter.html#details), and\n",
    "* [sitk.RegionOfInterest](https://itk.org/SimpleITKDoxygen/html/classitk_1_1simple_1_1RegionOfInterestImageFilter.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(sitk.LabelShapeStatisticsImageFilter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_shape_filter = sitk.LabelShapeStatisticsImageFilter()\n",
    "inside_value = 0\n",
    "outside_value = 1\n",
    "otsu_filter.SetInsideValue(inside_value)\n",
    "otsu_filter.SetOutsideValue(outside_value)\n",
    "label_shape_filter.Execute( otsu_filter.Execute(img_ct))\n",
    "bounding_box = label_shape_filter.GetBoundingBox(outside_value)\n",
    "print(bounding_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(sitk.RegionOfInterest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myORI = sitk.RegionOfInterest(img_ct, bounding_box[int(len(bounding_box)/2):], bounding_box[0:int(len(bounding_box)/2)])\n",
    "myshow(myORI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These filters compute a threshold based on some heuristic and apply that threshold to the input image using the [BinaryThresholdImageFilter](https://itk.org/Doxygen/html/classitk_1_1BinaryThresholdImageFilter.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many other histogram based automatic thresholding filters are implemented in SimpleITK, including\n",
    "* [Huang's thresholding method](https://www.sciencedirect.com/science/article/pii/0031320394E0043K): separates an image into foreground and background component by minimizing the measures of fuzziness,\n",
    "* [Traingle](http://journals.sagepub.com/doi/pdf/10.1177/25.7.70454): constructs a line between the histogram peak and the farthest end of the histogram. The threshold is the point of maximum distance between the line and the hidtogramm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Region Growing Segmentation\n",
    "\n",
    "It is reasonable that the same class of tissue would exhibit similar pixel intensity within the image. If a **seed** is given, we can group a class of pixels that are similar (by some statistical measures) and in the neighbourhood of the seed. In SimpleITK, thse are some of the filters that perform region growing segmentation:\n",
    "* <b>ConnectedThreshold</b>: The neighboring voxel's intensity is within explicitly specified thresholds.\n",
    "* <b>ConfidenceConnected</b>: The neighboring voxel's intensity is within the implicitly specified bounds $\\mu\\pm c\\sigma$, where $\\mu$ is the mean intensity of the seed points, $\\sigma$ their standard deviation and $c$ a user specified constant.\n",
    "* <b>VectorConfidenceConnected</b>: A generalization of the previous approach to vector valued images, for instance multi-spectral images or multi-parametric MRI. The neighboring voxel's intensity vector is within the implicitly specified bounds using the Mahalanobis distance $\\sqrt{(\\mathbf{x}-\\mathbf{\\mu})^T\\Sigma^{-1}(\\mathbf{x}-\\mathbf{\\mu})}<c$, where $\\mathbf{\\mu}$ is the mean of the vectors at the seed points, $\\Sigma$ is the covariance matrix and $c$ is a user specified constant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = (100, 170)\n",
    "seg = sitk.Image(img_ct.GetSize(), sitk.sitkUInt8)\n",
    "seg.CopyInformation(img_ct)\n",
    "seg[seed] = 1\n",
    "seg = sitk.BinaryDilate(seg, 3)\n",
    "myshow(sitk.LabelOverlay(img_255, seg), \"Initial Seed\")\n",
    "print(img_ct.GetPixel(seed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us experiment what each filter does. Staring with the ConnectedThreshold filter:\n",
    "<ul>\n",
    "  <li><a href=\"http://www.itk.org/Doxygen/html/classitk_1_1ConnectedThresholdImageFilter.html\">ConnectedThreshold</a>: Label pixels that are connected to a seed and lie within a range of values.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(sitk.ConnectedThreshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg = sitk.ConnectedThreshold(img_ct, seedList=[seed], lower=230, upper=255)\n",
    "myshow(sitk.LabelOverlay(img_255,seg), \"Connected Threshold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ConnectedThreshold filter:\n",
    "<ul>\n",
    "<li><a href=\"http://www.itk.org/Doxygen/html/classitk_1_1ConfidenceConnectedImageFilter.html\">ConfidenceConnected</a>: Segment pixels with similar statistics using connectivity.\n",
    "\n",
    "This filter extracts a connected set of pixels whose pixel intensities are consistent with the pixel statistics of a seed point. The mean and variance across a neighborhood (8-connected, 26-connected, etc.) are calculated for a seed point. Then pixels connected to this seed point whose values are within the confidence interval for the seed point are grouped. The width of the confidence interval is controlled by the \"Multiplier\" variable (the confidence interval is the mean plus or minus the \"Multiplier\" times the standard deviation). If the intensity variations across a segment were gaussian, a \"Multiplier\" setting of 2.5 would define a confidence interval wide enough to capture 99% of samples in the segment.\n",
    "\n",
    "After this initial segmentation is calculated, the mean and variance are re-calculated. All the pixels in the previous segmentation are used to calculate the mean the standard deviation (as opposed to using the pixels in the neighborhood of the seed point). The segmentation is then recalculated using these refined estimates for the mean and variance of the pixel values. This process is repeated for the specified number of iterations. Setting the \"NumberOfIterations\" to zero stops the algorithm after the initial segmentation from the seed point.\n",
    "\n",
    "NOTE: the lower and upper threshold are restricted to lie within the valid numeric limits of the input data pixel type. Also, the limits may be adjusted to contain the seed point's intensity.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(sitk.ConfidenceConnected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The VectorConfidenceConnected filter:\n",
    "<ul>\n",
    "<li><a href=\"http://www.itk.org/Doxygen/html/classitk_1_1VectorConfidenceConnectedImageFilter.html\">VectorConfidenceConnected</a>: same as the Confidence Connected Image filter but the the pixel type is of vector type.</li>\n",
    "</ul>\n",
    "\n",
    "As an example, if we have multi-model image of the same anatomy (T1 and T2 weighted of a brain, as an example), we can segment this image using statistics based on the multi-modality image."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
